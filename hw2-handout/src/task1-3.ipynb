{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import gc\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import string\n",
    "from collections import Counter\n",
    "from liblinear.liblinearutil import *\n",
    "from rmlr123 import rmlr123\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Number of stopwords: 341\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# Define paths\n",
    "train_root = 'data/yelp_reviews_train.json'\n",
    "test_root = 'data/yelp_reviews_test.json'\n",
    "val_root = 'data/yelp_reviews_dev.json'\n",
    "stopword_root = 'data/stopword.list'\n",
    "\n",
    "# Token pattern\n",
    "TOKEN_PATTERN = re.compile(r'\\b[a-z]+\\b')\n",
    "\n",
    "with open(stopword_root, 'r') as f:\n",
    "    stopwords = {line.strip() for line in f}\n",
    "print(f\"Number of stopwords: {len(stopwords)}\")\n",
    "\n",
    "translator = str.maketrans('', '', string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_tokenize(text, stopwords, translator, token_pattern):\n",
    "    text = text.lower().translate(translator)\n",
    "    tokens = token_pattern.findall(text)\n",
    "    return [token for token in tokens if token not in stopwords]\n",
    "\n",
    "# Function to load training data and extract texts and stars\n",
    "def load_training_data(file_path):\n",
    "    texts, stars = [], []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in tqdm(f, desc=f\"Loading data from {file_path}\"):\n",
    "            review = json.loads(line)\n",
    "            texts.append(review['text'])\n",
    "            stars.append(review['stars'])\n",
    "    return texts, np.array(stars)\n",
    "\n",
    "# Function to load text data (for test and validation sets)\n",
    "def load_text_data(file_path):\n",
    "    texts = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in tqdm(f, desc=f\"Loading data from {file_path}\"):\n",
    "            review = json.loads(line)\n",
    "            texts.append(review['text'])\n",
    "    return texts\n",
    "\n",
    "# Function to tokenize text data\n",
    "def tokenize_texts(texts, stopwords, translator, token_pattern):\n",
    "    return [clean_and_tokenize(text, stopwords, translator, token_pattern) for text in tqdm(texts, desc=\"Tokenizing texts\")]\n",
    "\n",
    "# Function to count document frequencies (DF) or collection term frequencies (CTF)\n",
    "def count_frequencies(tokenized_texts, use_unique_tokens=False):\n",
    "    token_counter = Counter()\n",
    "    for tokens in tqdm(tokenized_texts, desc=\"Counting tokens\"):\n",
    "        if use_unique_tokens:\n",
    "            tokens = set(tokens)  # Unique tokens for DF\n",
    "        token_counter.update(tokens)\n",
    "    return token_counter\n",
    "\n",
    "def create_feature_matrix(tokenized_texts, token_to_idx, num_features, binary=False):\n",
    "    \"\"\"\n",
    "    Creates a dense feature matrix for the input data.\n",
    "\n",
    "    Args:\n",
    "        tokenized_texts (list of list of str): Tokenized texts.\n",
    "        token_to_idx (dict): Token to index mapping.\n",
    "        num_features (int): Number of features (e.g., vocabulary size).\n",
    "        binary (bool): If True, use binary presence; else use term frequencies.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Dense feature matrix of shape (num_documents, num_features).\n",
    "    \"\"\"\n",
    "    num_documents = len(tokenized_texts)\n",
    "    feature_matrix = np.zeros((num_documents, num_features), dtype=np.float32)\n",
    "    \n",
    "    for doc_idx, tokens in enumerate(tqdm(tokenized_texts, desc=\"Creating feature matrix\")):\n",
    "        token_counts = Counter(tokens)\n",
    "        for token, count in token_counts.items():\n",
    "            if token in token_to_idx:\n",
    "                token_idx = token_to_idx[token]\n",
    "                if binary:\n",
    "                    feature_matrix[doc_idx, token_idx] = 1.0\n",
    "                else:\n",
    "                    feature_matrix[doc_idx, token_idx] += count\n",
    "    return feature_matrix\n",
    "\n",
    "# Function to display top tokens and star rating distribution\n",
    "def display_statistics(tokenized_texts, stars):\n",
    "    # Counting token frequencies\n",
    "    print(\"\\nCounting token frequencies...\")\n",
    "    token_counter = Counter()\n",
    "    for tokens in tqdm(tokenized_texts, desc=\"Counting token frequencies\"):\n",
    "        token_counter.update(tokens)\n",
    "\n",
    "    # Top 9 most frequent tokens\n",
    "    top_9 = token_counter.most_common(9)\n",
    "    print(\"\\nTop 9 Most Frequent Tokens:\")\n",
    "    print(\"{:<5} {:<15} {:<10}\".format('Rank', 'Token', 'Count'))\n",
    "    for rank, (token, count) in enumerate(top_9, start=1):\n",
    "        print(\"{:<5} {:<15} {:<10}\".format(rank, token, count))\n",
    "\n",
    "    # Star rating distribution\n",
    "    star_distribution = Counter(stars)\n",
    "    total_reviews = len(stars)\n",
    "    \n",
    "    print(\"\\nStar Rating Distribution:\")\n",
    "    print(\"{:<5} {:<10} {:<10}\".format('Star', 'Count', 'Percentage (%)'))\n",
    "    for star, count in sorted(star_distribution.items()):\n",
    "        percentage = (count / total_reviews) * 100\n",
    "        print(\"{:<5} {:<10} {:<10.2f}\".format(star, count, percentage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main processing function\n",
    "def main_processing(train_root, test_root, val_root, stopwords, translator, token_pattern):\n",
    "    # Load training, test, and dev data\n",
    "    train_texts, stars = load_training_data(train_root)\n",
    "    test_texts = load_text_data(test_root)\n",
    "    dev_texts = load_text_data(val_root)\n",
    "\n",
    "    # Tokenize texts\n",
    "    tokenized_train = tokenize_texts(train_texts, stopwords, translator, token_pattern)\n",
    "    tokenized_test = tokenize_texts(test_texts, stopwords, translator, token_pattern)\n",
    "    tokenized_dev = tokenize_texts(dev_texts, stopwords, translator, token_pattern)\n",
    "\n",
    "    # Count document frequencies (DF)\n",
    "    print(\"Counting document frequencies (DF)...\")\n",
    "    df_counter = count_frequencies(tokenized_train, use_unique_tokens=True)\n",
    "    top_2000_df = [token for token, _ in df_counter.most_common(2000)]\n",
    "    token_to_idx_df = {token: idx for idx, token in enumerate(top_2000_df)}\n",
    "\n",
    "    # Create sparse DF feature matrices for train, dev, and test sets\n",
    "    print(\"Creating sparse DF feature matrices...\")\n",
    "    num_features = len(top_2000_df)\n",
    "    features_df_train = create_feature_matrix(tokenized_train, token_to_idx_df, num_features)\n",
    "    features_df_dev = create_feature_matrix(tokenized_dev, token_to_idx_df, num_features)\n",
    "    features_df_test = create_feature_matrix(tokenized_test, token_to_idx_df, num_features)\n",
    "\n",
    "    # Count collection term frequencies (CTF)\n",
    "    print(\"Counting collection term frequencies (CTF)...\")\n",
    "    ctf_counter = count_frequencies(tokenized_train)\n",
    "    top_2000_ctf = [token for token, _ in ctf_counter.most_common(2000)]\n",
    "    token_to_idx_ctf = {token: idx for idx, token in enumerate(top_2000_ctf)}\n",
    "\n",
    "    # Create sparse CTF feature matrices for train, dev, and test sets\n",
    "    print(\"Creating sparse CTF feature matrices...\")\n",
    "    features_ctf_train = create_feature_matrix(tokenized_train, token_to_idx_ctf, num_features)\n",
    "    features_ctf_dev = create_feature_matrix(tokenized_dev, token_to_idx_ctf, num_features)\n",
    "    features_ctf_test = create_feature_matrix(tokenized_test, token_to_idx_ctf, num_features)\n",
    "\n",
    "    # Print feature matrix shapes for verification\n",
    "    print(f\"DF feature matrix shapes: train={features_df_train.shape}, dev={features_df_dev.shape}, test={features_df_test.shape}\")\n",
    "    print(f\"CTF feature matrix shapes: train={features_ctf_train.shape}, dev={features_ctf_dev.shape}, test={features_ctf_test.shape}\")\n",
    "\n",
    "    return features_df_train, features_df_dev, features_df_test, features_ctf_train, features_ctf_dev, features_ctf_test, stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data from data/yelp_reviews_train.json: 1255353it [00:13, 94694.32it/s]\n",
      "Loading data from data/yelp_reviews_test.json: 156901it [00:01, 100413.73it/s]\n",
      "Loading data from data/yelp_reviews_dev.json: 157010it [00:01, 100900.53it/s]\n",
      "Tokenizing texts: 100%|██████████| 1255353/1255353 [01:59<00:00, 10508.96it/s]\n",
      "Tokenizing texts: 100%|██████████| 156901/156901 [00:11<00:00, 13504.92it/s]\n",
      "Tokenizing texts: 100%|██████████| 157010/157010 [00:27<00:00, 5623.68it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting document frequencies (DF)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Counting tokens: 100%|██████████| 1255353/1255353 [00:24<00:00, 51565.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating sparse DF feature matrices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature matrix: 100%|██████████| 1255353/1255353 [03:50<00:00, 5438.95it/s]\n",
      "Creating feature matrix: 100%|██████████| 157010/157010 [00:28<00:00, 5541.14it/s]\n",
      "Creating feature matrix: 100%|██████████| 156901/156901 [00:28<00:00, 5501.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting collection term frequencies (CTF)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Counting tokens: 100%|██████████| 1255353/1255353 [00:18<00:00, 68565.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating sparse CTF feature matrices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature matrix: 100%|██████████| 1255353/1255353 [03:50<00:00, 5450.70it/s]\n",
      "Creating feature matrix: 100%|██████████| 157010/157010 [00:28<00:00, 5556.77it/s]\n",
      "Creating feature matrix: 100%|██████████| 156901/156901 [00:28<00:00, 5522.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF feature matrix shapes: train=(1255353, 2000), dev=(157010, 2000), test=(156901, 2000)\n",
      "CTF feature matrix shapes: train=(1255353, 2000), dev=(157010, 2000), test=(156901, 2000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Call main processing function with appropriate arguments\n",
    "features_df_train, features_df_dev, features_df_test, features_ctf_train, features_ctf_dev, features_ctf_test, stars = main_processing(\n",
    "    train_root, test_root, val_root, stopwords, translator, TOKEN_PATTERN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model with LibLinear\n",
    "liblinear_params = {\n",
    "    'solver_type': L2R_LR,  # L2-regularized logistic regression\n",
    "    'C': 1.0,               # Regularization parameter\n",
    "    'eps': 0.01,            # Stopping criteria\n",
    "    'verbose': False        # Disable verbose output\n",
    "}\n",
    "\n",
    "# Wrapping LibLinear training and prediction in tqdm\n",
    "\n",
    "# Train LibLinear model using DF and CTF features\n",
    "print(\"Training LibLinear models...\")\n",
    "\n",
    "with tqdm(total=2, desc=\"Training models\") as pbar:\n",
    "    # Train the model for DF features\n",
    "    model_df = train(stars, features_df_train, f\"-s {liblinear_params['solver_type']} -c {liblinear_params['C']} -e {liblinear_params['eps']} -q\")\n",
    "    pbar.update(1)  # Progress after training DF model\n",
    "    print(\"LibLinear model training completed for DF features.\")\n",
    "\n",
    "    # Train the model for CTF features\n",
    "    model_ctf = train(stars, features_ctf_train, f\"-s {liblinear_params['solver_type']} -c {liblinear_params['C']} -e {liblinear_params['eps']} -q\")\n",
    "    pbar.update(1)  # Progress after training CTF model\n",
    "    print(\"LibLinear model training completed for CTF features.\")\n",
    "\n",
    "# Making predictions with DF and CTF models\n",
    "print(\"Making predictions using LibLinear models...\")\n",
    "\n",
    "with tqdm(total=2, desc=\"Making predictions\") as pbar:\n",
    "    # Predictions using DF features\n",
    "    y_hard_train_df, accuracy_train_df, y_soft_train_df = predict(stars, features_df_train, model_df, '-b 1')\n",
    "    pbar.update(1)  # Progress after DF predictions\n",
    "    print(f\"Training Accuracy (DF Features): {accuracy_train_df[0]}%\")\n",
    "\n",
    "    # Predictions using CTF features\n",
    "    y_hard_train_ctf, accuracy_train_ctf, y_soft_train_ctf = predict(stars, features_ctf_train, model_ctf, '-b 1')\n",
    "    pbar.update(1)  # Progress after CTF predictions\n",
    "    print(f\"Training Accuracy (CTF Features): {accuracy_train_ctf[0]}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for the development set using the trained LibLinear models\n",
    "y_hard_dev_df, _, y_soft_dev_df = predict([], features_df_dev, model_df, '-b 1')\n",
    "y_hard_dev_ctf, _, y_soft_dev_ctf = predict([], features_ctf_dev, model_ctf, '-b 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions(file_name, y_hard, y_soft):\n",
    "    \"\"\"\n",
    "    Saves predictions to a text file in the required format.\n",
    "\n",
    "    Each line in the file will contain:\n",
    "    <hard_prediction> <soft_prediction>\n",
    "    \n",
    "    Parameters:\n",
    "    - file_name (str): The name of the output file.\n",
    "    - y_hard (list of float): List of hard predictions.\n",
    "    - y_soft (list of list of float): List of soft predictions (probabilities).\n",
    "    \"\"\"\n",
    "    with open(file_name, 'w') as f:\n",
    "        for hard, soft_probs in zip(y_hard, y_soft):\n",
    "            hard_int = int(hard)  # Convert hard prediction to integer\n",
    "            \n",
    "            # Safely retrieve the soft prediction\n",
    "            soft = soft_probs[hard_int] if 0 <= hard_int < len(soft_probs) else 0.0\n",
    "            \n",
    "            # Write hard and soft predictions in the required format\n",
    "            f.write(f\"{hard_int} {soft:.4f}\\n\")\n",
    "\n",
    "# Validate that the predictions have the expected number of lines\n",
    "def validate_predictions(y_hard, y_soft, required_lines):\n",
    "    \"\"\"\n",
    "    Validates the length of hard and soft predictions.\n",
    "    \n",
    "    Parameters:\n",
    "    - y_hard (list): Hard predictions.\n",
    "    - y_soft (list): Soft predictions.\n",
    "    - required_lines (int): Expected number of lines.\n",
    "    \n",
    "    Raises an assertion error if the lengths don't match the required number of lines.\n",
    "    \"\"\"\n",
    "    assert len(y_hard) == required_lines, f\"Hard predictions should have {required_lines} lines.\"\n",
    "    assert len(y_soft) == required_lines, f\"Soft predictions should have {required_lines} lines.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_dev_lines = 157010\n",
    "\n",
    "# Validate DF predictions\n",
    "validate_predictions(y_hard_dev_df, y_soft_dev_df, required_dev_lines)\n",
    "\n",
    "# Validate CTF predictions\n",
    "validate_predictions(y_hard_dev_ctf, y_soft_dev_ctf, required_dev_lines)\n",
    "\n",
    "# Save predictions for Development Set (DF and CTF)\n",
    "#save_predictions(\"dev-predictions-df-svm.txt\", y_hard_dev_df, y_soft_dev_df)\n",
    "#save_predictions(\"dev-predictions-ctf-svm.txt\", y_hard_dev_ctf, y_soft_dev_ctf)\n",
    "\n",
    "print(\"Prediction files generated successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import importlib\n",
    "#import rmlr123\n",
    "#importlib.reload(rmlr123)\n",
    "\n",
    "#Stop times needing to reload module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Loss: 1.4075 - Accuracy: 50.66%\n",
      "    Validation Loss: 1.4016 - Validation Accuracy: 50.92%\n",
      "Epoch 2/5 - Loss: 1.4009 - Accuracy: 51.22%\n",
      "    Validation Loss: 1.4016 - Validation Accuracy: 50.76%\n",
      "Epoch 3/5 - Loss: 1.4009 - Accuracy: 51.20%\n",
      "    Validation Loss: 1.4016 - Validation Accuracy: 51.15%\n",
      "Epoch 4/5 - Loss: 1.4009 - Accuracy: 51.23%\n",
      "    Validation Loss: 1.4016 - Validation Accuracy: 50.67%\n",
      "Epoch 5/5 - Loss: 1.4009 - Accuracy: 51.23%\n",
      "    Validation Loss: 1.4015 - Validation Accuracy: 50.75%\n",
      "Validation Accuracy (DF): 50.75%\n",
      "RMSE (DF Training Set): 1.1930\n",
      "Epoch 1/10 - Loss: 1.4076 - Accuracy: 50.64%\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode_labels(stars, num_classes=5):\n",
    "    one_hot_labels = np.zeros((len(stars), num_classes))\n",
    "    for idx, star in enumerate(stars):\n",
    "        one_hot_labels[idx, star - 1] = 1  # stars are 1-indexed, hence subtracting 1\n",
    "    return one_hot_labels\n",
    "\n",
    "# One-hot encode star ratings\n",
    "y_one_hot = one_hot_encode_labels(stars)\n",
    "\n",
    "# Train the RMLR model using DF features\n",
    "num_classes = 5  # For 5-star ratings\n",
    "learning_rate = 0.01\n",
    "lambda_reg = 0.1\n",
    "class_weights = np.ones(num_classes)  # Adjust if you have class imbalance\n",
    "num_features = features_df_train.shape[1]\n",
    "\n",
    "model_df = rmlr123(num_features=num_features, num_classes=num_classes,\n",
    "                   learning_rate=learning_rate, lambda_reg=lambda_reg,\n",
    "                   class_weights=class_weights)\n",
    "\n",
    "X_train_df, X_val_df, Y_train_df, Y_val_df = train_test_split(features_df_train, y_one_hot, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model_df.train(X_train_df, Y_train_df, X_val=X_val_df, Y_val=Y_val_df, epochs=15, batch_size=100, verbose=True)\n",
    "\n",
    "# Evaluate on validation data\n",
    "val_accuracy_df = model_df.evaluate_accuracy(X_val_df, Y_val_df)\n",
    "print(f\"Validation Accuracy (DF): {val_accuracy_df:.2f}%\")\n",
    "\n",
    "# Predict soft values for RMSE calculation on training set\n",
    "soft_predictions_train_df = model_df.predict_soft(X_train_df)\n",
    "\n",
    "# Calculate the true labels from one-hot encoding (convert one-hot back to integer values)\n",
    "true_labels_train_df = np.argmax(Y_train_df, axis=1) + 1  # Add 1 to match 1-5 stars\n",
    "\n",
    "# Calculate RMSE on DF training data\n",
    "rmse_df = np.sqrt(mean_squared_error(true_labels_train_df, soft_predictions_train_df))\n",
    "print(f\"RMSE (DF Training Set): {rmse_df:.4f}\")\n",
    "\n",
    "\n",
    "# --------------- Train and Evaluate CTF Model -----------------\n",
    "\n",
    "# Train the RMLR model using CTF features\n",
    "num_features_ctf = features_ctf_train.shape[1]\n",
    "\n",
    "model_ctf = rmlr123(num_features=num_features_ctf, num_classes=num_classes,\n",
    "                    learning_rate=learning_rate, lambda_reg=lambda_reg,\n",
    "                    class_weights=class_weights)\n",
    "\n",
    "X_train_ctf, X_val_ctf, Y_train_ctf, Y_val_ctf = train_test_split(features_ctf_train, y_one_hot, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model_ctf.train(X_train_ctf, Y_train_ctf, X_val=X_val_ctf, Y_val=Y_val_ctf, epochs=10, batch_size=100, verbose=True)\n",
    "\n",
    "# Evaluate on validation data\n",
    "val_accuracy_ctf = model_ctf.evaluate_accuracy(X_val_ctf, Y_val_ctf)\n",
    "print(f\"Validation Accuracy (CTF): {val_accuracy_ctf:.2f}%\")\n",
    "\n",
    "# Predict soft values for RMSE calculation on training set\n",
    "soft_predictions_train_ctf = model_ctf.predict_soft(X_train_ctf)\n",
    "\n",
    "# Calculate the true labels from one-hot encoding (convert one-hot back to integer values)\n",
    "true_labels_train_ctf = np.argmax(Y_train_ctf, axis=1) + 1  # Add 1 to match 1-5 stars\n",
    "\n",
    "# Calculate RMSE on CTF training data\n",
    "rmse_ctf = np.sqrt(mean_squared_error(true_labels_train_ctf, soft_predictions_train_ctf))\n",
    "print(f\"RMSE (CTF Training Set): {rmse_ctf:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions(model, X, output_file):\n",
    "    \"\"\"\n",
    "    Generate hard and soft predictions for a dataset and write them to a file.\n",
    "\n",
    "    Args:\n",
    "        model (rmlr123): Trained RMLR model.\n",
    "        X (np.ndarray): Feature matrix for the dataset (dev or test set).\n",
    "        output_file (str): Path to the output file to write predictions.\n",
    "    \"\"\"\n",
    "    hard_predictions = model.predict_hard(X)  # Hard predictions\n",
    "    soft_predictions = model.predict_soft(X)  # Soft predictions\n",
    "\n",
    "    with open(output_file, 'w') as f:\n",
    "        for hard_pred, soft_pred in zip(hard_predictions, soft_predictions):\n",
    "            f.write(f\"{hard_pred} {soft_pred:.4f}\\n\")  # Write hard and soft prediction\n",
    "\n",
    "X_dev = features_ctf_dev  # Replace with your actual dev set features\n",
    "X_test = features_ctf_test  # Replace with your actual test set features\n",
    "\n",
    "# Generate predictions for development and test sets\n",
    "#generate_predictions(model_ctf, X_dev, \"dev-predictions-ctf.txt\")\n",
    "#generate_predictions(model_ctf, X_test, \"test-predictions-ctf.txt\")\n",
    "\n",
    "X_dev = features_df_dev  # Replace with your actual dev set features\n",
    "X_test = features_df_test  # Replace with your actual test set features\n",
    "\n",
    "# Generate predictions for development and test sets\n",
    "#generate_predictions(model_df, X_dev, \"dev-predictions-df.txt\")\n",
    "#generate_predictions(model_df, X_test, \"test-predictions-df.txt\")\n",
    "\n",
    "print(\"Prediction files generated successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
